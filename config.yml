###############################################################################
# SET GENERAL PARAMETERS
###############################################################################
EXECUTABLE: walker_grav_win
STEPS: 1000000
VERBOSE_STEPS: 1000
CHECKPOINTS: 50000
NO_GRAPHICS: False
UTILIZE_CUDA: True
TIME_SCALE: 20.0
ENVIRONMENTS: 1 
#Gravity is only working when used with the prebuilt walker environment from the repo
#Earth:     9.81
#Moon:      1.62
#Jupiter:   24.79
GRAVITY: 9.81
#Leave empty for auto mode
SUMMARY_FOLDER:

LAYER_SIZES:
  - 256
  - 256
  - 256

###############################################################################
# SET PARAMETERS FOR TRAINING WITH PPO
###############################################################################
PPO_BUFFER_SIZE: 20480
PPO_BATCH_SIZE: 2048
PPO_EPOCHS: 3

PPO_STD: 0.0


PPO_GAMMA: 0.99
PPO_LAMBDA: 0.95
PPO_EPSILON: 0.2
CRITIC_DISCOUNT: 0.5
ENTROPY_BETA: 0.00001

PPO_ACTOR_LEARNING_RATE: 0.001
PPO_CRITIC_LEARNING_RATE: 0.001

###############################################################################
# SET PARAMETERS FOR HYPERPARAMETER SEARCH WITH PPO
###############################################################################

# Number of times the environment is tested with new parameters
OPT_PPO_RUNS: 25

OPT_PPO_STEPS: 300000
OPT_PPO_CHECKPOINTS: 50000
OPT_PPO_VERBOSE_STEPS: 5000

# Multiple of batch size
# (=min (BUFFER_SIZE * BATCH_SIZE, 409600)
# Uniform range (int)
OPT_PPO_BUFFER_SIZE: [4, 400]
# Choices
OPT_PPO_BATCH_SIZE: [512, 1024, 2048, 4096]
# Uniform distr range (int)
OPT_PPO_EPOCHS: [3, 10]
# Uniform distr range (float)
OPT_PPO_STD: [-3.0 , 0.0]
# Uniform distr range (float)
OPT_PPO_GAMMA: [0.9, 0.9999]
# Uniform distr range (float)
OPT_PPO_LAMBDA: [0.85, 0.99]
# Uniform range (float)
OPT_PPO_EPSILON: [0.05, 0.5]
# Uniform range (float)
OPT_CRITIC_DISCOUNT: [0.1, 1.0]
# Uniform distr range (float)
OPT_ENTROPY_BETA: [0.0001, 0.01]
# Uniform distr range (float)
OPT_PPO_ACTOR_LEARNING_RATE: [0.00001, 0.001]
# Uniform distr range (float)
OPT_PPO_CRITIC_LEARNING_RATE: [0.00001, 0.001]

###############################################################################
# SET PARAMETERS FOR TRAINING WITH DDPG
###############################################################################
OUNOISE: False

GAUSSIAN_START: 1.0
GAUSSIAN_DECAY: 0.8
GAUSSIAN_MIN: 0.1

BUFFER_SIZE: 50000
BATCH_SIZE: 32

ACTOR_LEARNING_RATE: 0.0001
CRITIC_LEARNING_RATE: 0.0001

TAU: 0.9999
GAMMA: 0.99

###############################################################################
# SET PARAMETERS FOR HYPERPARAMETER SEARCH WITH DDPG
###############################################################################

# Number of times the environment is tested with new parameters
OPT_DDPG_RUNS: 100

OPT_DDPG_STEPS: 300000
OPT_DDPG_CHECKPOINTS: 50000
OPT_DDPG_VERBOSE_STEPS: 5000


#Uniform range (float)
OPT_DDPG_GAUSS_START: [0.5, 1.0]
#Uniform range (float)
OPT_DDPG_GAUSS_DECAY: [0.5, 0.9]
#Uniform range (float)
OPT_DDPG_GAUSS_MIN: [0.05, 0.25]

# Uniform range (int)
OPT_DDPG_BUFFER_SIZE: [10000, 1000000]
# Choices
OPT_DDPG_BATCH_SIZE: [16, 32, 64]

# Uniform distr range (float)
OPT_DDPG_ACTOR_LEARNING_RATE: [0.00001, 0.001]
# Uniform distr range (float)
OPT_DDPG_CRITIC_LEARNING_RATE: [0.00001, 0.001]

# Uniform range (float)
OPT_DDPG_TAU: [0.99, 0.99999]
# Uniform distr range (float)
OPT_DDPG_GAMMA: [0.98, 0.999]

###############################################################################
# SET PARAMETERS FOR RUN
###############################################################################
RUN_EXECUTABLE: crawler
RUN_MODEL: models/vm_crawler/actor_3000000.pt
RUN_STEPS: 10000
RUN_VERBOSE_STEPS: 1000
RUN_NO_GRAPHICS: False
